{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3b6d6cdc",
   "metadata": {},
   "source": [
    "# ðŸ§­ Governance Adherence Ratio (GAR) â€” Quickstart Replication Notebook\n",
    "Welcome to the **GAR Replication Challenge (v1.0)** by *Osiris Research LLC*.\n",
    "\n",
    "This notebook is designed to:\n",
    "1. **Run quickly** â€” reproduce headline GAR and DDI results in <10 min.  \n",
    "2. **Teach** â€” explain what each metric measures and why it matters.  \n",
    "3. **Verify** â€” output a small `verification_result.json` youâ€™ll submit for your badge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f097fa",
   "metadata": {},
   "source": [
    "### âš™ï¸ 0. Setup\n",
    "Install required packages and import modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5258b24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas numpy statsmodels\n",
    "import pandas as pd, numpy as np, json, time, sys\n",
    "from pathlib import Path\n",
    "print(\"Python:\", sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5f2c7c",
   "metadata": {},
   "source": [
    "### ðŸ“¦ 1. Load data\n",
    "Two small CSVs are included:  \n",
    "- `sample_returns.csv` â€” portfolio or fund returns  \n",
    "- `sample_factors.csv` â€” benchmark factors\n",
    "\n",
    "The data are synthetic and safe for research use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93aad207",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path(\"data\")\n",
    "rets = pd.read_csv(path/\"sample_returns.csv\", parse_dates=[\"date\"])\n",
    "factors = pd.read_csv(path/\"sample_factors.csv\", parse_dates=[\"date\"])\n",
    "print(f\"Returns shape: {rets.shape}, Factors shape: {factors.shape}\")\n",
    "rets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1153397",
   "metadata": {},
   "source": [
    "### ðŸ§  2. Learn the Concept\n",
    "\n",
    "- **GAR** measures *how closely real decisions follow pre-stated rules*.  \n",
    "  Think of it like a â€œdiscipline ratioâ€: 1 = perfect rule-following, lower = more improvisation.  \n",
    "- **DDI** measures *how fast discipline decays over time* â€” drift or entropy.  \n",
    "\n",
    "Weâ€™ll now compute illustrative values using simplified formulas (details proprietary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e45bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simplified demo computation for educational purposes\n",
    "def compute_gar(df):\n",
    "    # dummy logic: inverse of deviation from rolling mean\n",
    "    diff = (df[\"return\"] - df[\"return\"].rolling(10, min_periods=5).mean()).abs()\n",
    "    gar = 1 - diff.mean() / diff.max()\n",
    "    return max(0, min(1, gar))\n",
    "\n",
    "def compute_ddi(df):\n",
    "    # dummy drift indicator: rolling std normalized\n",
    "    drift = df[\"return\"].rolling(10, min_periods=5).std()\n",
    "    ddi = drift.mean() / drift.max()\n",
    "    return float(ddi)\n",
    "\n",
    "GAR = compute_gar(rets)\n",
    "DDI = compute_ddi(rets)\n",
    "print(f\"GAR = {GAR:.3f}, DDI = {DDI:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506fa68a",
   "metadata": {},
   "source": [
    "### ðŸ§© 3. Verification Step\n",
    "\n",
    "This compares your results with the expected headline values in\n",
    "`data/expected_headlines.json` and prints whether you passed tolerance thresholds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6fb2beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected = json.load(open(path/\"expected_headlines.json\"))\n",
    "tol = {\"gar\":0.01, \"ddi\":0.02}\n",
    "\n",
    "delta_gar = abs(GAR - expected[\"gar\"])\n",
    "delta_ddi = abs(DDI - expected[\"ddi\"])\n",
    "\n",
    "headline_pass = (delta_gar <= tol[\"gar\"]) and (delta_ddi <= tol[\"ddi\"])\n",
    "\n",
    "result = {\n",
    "    \"timestamp_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "    \"gar\": round(GAR,4),\n",
    "    \"gar_expected\": expected[\"gar\"],\n",
    "    \"gar_delta\": round(delta_gar,4),\n",
    "    \"ddi\": round(DDI,4),\n",
    "    \"ddi_expected\": expected[\"ddi\"],\n",
    "    \"ddi_delta\": round(delta_ddi,4),\n",
    "    \"headline_pass\": headline_pass,\n",
    "    \"python_version\": sys.version\n",
    "}\n",
    "print(json.dumps(result, indent=2))\n",
    "with open(\"verification_result.json\",\"w\") as f: json.dump(result,f,indent=2)\n",
    "print(\"\\nâœ… Verification file written to verification_result.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aa90612",
   "metadata": {},
   "source": [
    "### ðŸ§­ 4. Reflection â€” Short Learning Questions\n",
    "\n",
    "Before submitting, answer briefly:\n",
    "\n",
    "1ï¸âƒ£ *What does GAR measure in one sentence?*  \n",
    "2ï¸âƒ£ *What would prove GAR wrong?*  \n",
    "\n",
    "(Type your answers here â¬‡)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1acd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# leave blank for user text entry\n",
    "answers = {\n",
    "    \"q1\": \"GAR measures ________\",\n",
    "    \"q2\": \"GAR would be falsified if ________\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd1ffa3",
   "metadata": {},
   "source": [
    "### ðŸ“¤ 5. Submit Your Result\n",
    "\n",
    "Upload your `verification_result.json` using the link below  \n",
    "or email it to **replications@osirisresearch.com** with subject **GAR Replication v1 â€“ <Your Name>**.\n",
    "\n",
    "Passing participants receive a **GAR Replicator v1** badge\n",
    "and optional listing on the public replication dashboard.\n",
    "\n",
    "---\n",
    "\n",
    "ðŸ§© *For research and educational purposes only â€” not investment advice.*  \n",
    "Â© 2025 Osiris Research LLC.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
